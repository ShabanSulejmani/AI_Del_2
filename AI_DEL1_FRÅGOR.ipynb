{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb152e78",
   "metadata": {},
   "source": [
    "# Kunskapskontroll Del 1: Teori (Kapitel 1–4)\n",
    "\n",
    "**Namn:** Saban Sulejmani\n",
    "\n",
    "Detta är en sammanställning av teori för kapitel 1–4.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739fc3bb",
   "metadata": {},
   "source": [
    "## Innehåll\n",
    "- Kapitel 1 – Introduktion till Maskininlärning\n",
    "- Kapitel 2 – Datahantering\n",
    "- Kapitel 3 – Linjär Regression\n",
    "- Kapitel 4 – Klassificering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e1f6d",
   "metadata": {},
   "source": [
    "# Kapitel 1 – Introduktion till Maskininlärning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea30ecc5",
   "metadata": {},
   "source": [
    "## Faktafrågor\n",
    "\n",
    "### 1. Hur hänger AI, ML och DL ihop?\n",
    "Man kan se det som ryska dockor (cirklar inuti varandra):\n",
    "\n",
    "- **AI (Artificiell Intelligens):** Det bredaste begreppet. Det handlar om all teknik som får maskiner att efterlikna mänsklig intelligens (t.ex. logik, regler eller inlärning).\n",
    "- **ML (Maskininlärning):** En delmängd av AI. Här programmerar vi inte reglerna manuellt, utan algoritmen lär sig regler genom att titta på data.\n",
    "- **DL (Djupinlärning):** En delmängd av ML. Här använder vi specifikt artificiella neurala nätverk (ANN) med många lager för att lösa väldigt komplexa problem (som bildigenkänning).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744b212",
   "metadata": {},
   "source": [
    "### 2. Vilka är de fyra problemkategorierna inom ML?\n",
    "- **Supervised Learning (Övervakad inlärning):** Vi har facit. Datan består av input (X) och korrekt output (y). Exempel: Klassificera mail som \"Spam\" eller \"Ej spam\".\n",
    "- **Unsupervised Learning (Oövervakad inlärning):** Vi saknar facit. Modellen får leta mönster själv i datan. Exempel: Kundsegmentering (klustring).\n",
    "- **Semi-supervised Learning:** En blandning. Vi har mycket data, men bara en liten del har facit. Används ofta när det är dyrt att märka upp data (t.ex. medicinska bilder).\n",
    "- **Reinforcement Learning (Förstärkningsinlärning):** En agent lär sig genom \"trial and error\" i en miljö och får belöning eller straff. Exempel: En dator som lär sig spela schack.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05678b",
   "metadata": {},
   "source": [
    "### 3. Förklaring av begrepp\n",
    "\n",
    "**a) Syftet med Train/Val/Test-split**  \n",
    "Vi delar upp datan för att undvika att lura oss själva.\n",
    "\n",
    "- **Träningsdata:** Läroboken vi pluggar på.\n",
    "- **Valideringsdata:** Övningsprov vi gör under kursen för att stämma av (tune hyperparametrar).\n",
    "- **Testdata:** Det skarpa slutprovet. Denna data får modellen aldrig ha sett innan, för att vi ska veta hur den presterar i verkligheten.\n",
    "\n",
    "**b) K-delad korsvalidering (Cross-validation)**  \n",
    "Istället för att bara ha en träningsdel och en testdel, delar vi datan i K delar (t.ex. 5). Vi tränar K gånger. Varje gång agerar en ny del \"testdata\" och resten träningsdata.  \n",
    "Syfte: Ger ett mycket säkrare mått på hur bra modellen är, eftersom slumpen spelar mindre roll.\n",
    "\n",
    "**c) RMSE (Root Mean Squared Error)**  \n",
    "Ett mått på hur mycket fel vår modell gissar i genomsnitt (för regression).  \n",
    "Vi tar felet, kvadrerar det (för att straffa stora fel hårt), tar medelvärdet, och sen roten ur.  \n",
    "Lågt värde = bra modell.\n",
    "\n",
    "**d) Hyperparameter vs Parameter**  \n",
    "- **Parameter:** Det modellen lär sig själv under träningen (t.ex. vikterna i ett neuralt nätverk).\n",
    "- **Hyperparameter:** Inställningar vi bestämmer innan träningen börjar (t.ex. learning_rate, antal lager i nätverket, eller antal grannar i KNN).\n",
    "\n",
    "**e) Grid Search**  \n",
    "En metod för att hitta bästa hyperparametrarna.\n",
    "\n",
    "- **Grid:** Vi sätter upp ett rutnät av värden vi vill testa (t.ex. learning rate: 0.01, 0.1, 0.001).\n",
    "- **Search:** Datorn testar systematiskt alla kombinationer i rutnätet för att se vilken som ger bäst resultat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6149cce",
   "metadata": {},
   "source": [
    "## Resonemangsfrågor\n",
    "\n",
    "### Resonemang kring \"Bias-Variance Tradeoff\" (Överanpassning vs Underanpassning)\n",
    "- Om en modell är för enkel (hög bias/underfitting) missar den poängen, ungefär som att gissa att alla hus kostar 2 miljoner oavsett storlek.\n",
    "- Om en modell är för komplex (hög varians/overfitting) pluggar den in brus och tillfälligheter i träningsdatan. Det är som att memorera svaren på ett specifikt prov men misslyckas så fort frågorna formuleras om.\n",
    "- Målet: Hitta balansen (sweet spot) där modellen generaliserar bra på ny data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df816a",
   "metadata": {},
   "source": [
    "# Kapitel 2 – Datahantering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d75af58",
   "metadata": {},
   "source": [
    "## Faktafrågor\n",
    "\n",
    "### 1. Varför behöver vi skala (normalisera/standardisera) data?\n",
    "Många ML-algoritmer (särskilt de som bygger på avstånd, som KNN, eller gradient descent, som neurala nätverk) fungerar dåligt om variablerna har olika skalor.\n",
    "\n",
    "Exempel: Om \"Ålder\" är 0–100 och \"Lön\" är 20 000–50 000, kommer \"Lön\" att dominera matematiskt. Vi skalar om så båda hamnar runt 0–1 eller har samma spridning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffabc5",
   "metadata": {},
   "source": [
    "### 2. Standard Scaler vs MinMax Scaler\n",
    "- **MinMax Scaler:** Tvingar in alla värden mellan 0 och 1. Känslig för outliers (extrema värden).\n",
    "- **Standard Scaler:** Gör om datan så medelvärdet blir 0 och standardavvikelsen 1. Bättre om datan följer en normalfördelning eller har outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7cc5e",
   "metadata": {},
   "source": [
    "### 3. Hantering av kategorisk data (text till siffror)\n",
    "Datorer förstår bara siffror.\n",
    "\n",
    "- **Label Encoding:** Ger varje kategori en siffra (Röd=1, Blå=2, Grön=3). Problem: Modellen kan tro att Grön är \"större/bättre\" än Röd. Bra för ordnad data (Liten, Mellan, Stor).\n",
    "- **One-Hot Encoding:** Skapar en ny kolumn för varje kategori med 1 eller 0 (Är_Röd: 1, Är_Blå: 0). Tar mer plats men lurar inte modellen att tro på falsk rangordning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb4567",
   "metadata": {},
   "source": [
    "## Resonemangsfrågor\n",
    "\n",
    "### Resonemang kring saknad data (Missing Data)\n",
    "Om vi har hål i datan kan vi inte bara köra modellen. Vi har två huvudval:\n",
    "\n",
    "- **Ta bort:** Om vi har miljontals rader och bara några saknas, kan vi radera dem. Risk: Vi kanske kastar bort viktig info.\n",
    "- **Imputera (fylla i):** Vi ersätter det saknade värdet med medelvärdet (mean) eller medianen av kolumnen. Risk: Vi gissar, vilket inför en viss osäkerhet, men vi får behålla datan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb2561",
   "metadata": {},
   "source": [
    "# Kapitel 3 – Linjär Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa52367",
   "metadata": {},
   "source": [
    "## Faktafrågor\n",
    "\n",
    "### 1. Vad är Linjär Regression?\n",
    "En algoritm för att förutsäga ett numeriskt värde (regression). Den försöker dra en rät linje genom datapunkterna så att avståndet mellan linjen och punkterna minimeras.\n",
    "\n",
    "Formel:  \n",
    "\\[ y = kx + m \\]  \n",
    "(eller \\( y = w \\cdot x + b \\) i ML-språk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99417a7",
   "metadata": {},
   "source": [
    "### 2. Vad är en residual?\n",
    "Felet för en specifik punkt. Avståndet mellan det verkliga värdet (y) och det värde linjen förutspådde (ŷ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69295c",
   "metadata": {},
   "source": [
    "## Resonemangsfrågor\n",
    "\n",
    "### Resonemang kring korrelation\n",
    "Bara för att två saker korrelerar (följer varandra) betyder det inte att den ena orsakar den andra (kausalitet).\n",
    "\n",
    "Exempel: Glassförsäljning och drunkningsolyckor ökar samtidigt. Orsakar glass drunkning? Nej, båda styrs av en tredje faktor: värmen på sommaren.\n",
    "\n",
    "För ML betyder det att vi kan använda korrelation för prediktion, men vi ska vara försiktiga med att dra slutsatser om orsak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d178e2",
   "metadata": {},
   "source": [
    "# Kapitel 4 – Klassificering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03884462",
   "metadata": {},
   "source": [
    "## Faktafrågor\n",
    "\n",
    "### 1. Vad skiljer Regression från Klassificering?\n",
    "- **Regression:** Svaret är en siffra på en glidande skala (t.ex. pris på hus, temperatur).\n",
    "- **Klassificering:** Svaret är en kategori/klass (t.ex. katt/hund, sjuk/frisk, ja/nej).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075d152",
   "metadata": {},
   "source": [
    "### 2. Vad är Logistisk Regression?\n",
    "Trots namnet används den för klassificering.\n",
    "\n",
    "Den använder en sigmoid-funktion (S-kurva) för att klämma in resultatet mellan 0 och 1. Detta tolkas som sannolikheten för klassen (t.ex. 0.8 = 80% chans att det är spam).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca243e2e",
   "metadata": {},
   "source": [
    "### 3. Förklara Confusion Matrix (Konfusionsmatris)\n",
    "En tabell som visar hur modellen gissade jämfört med verkligheten.\n",
    "\n",
    "- **TP (True Positive):** Rätt gissat JA.\n",
    "- **TN (True Negative):** Rätt gissat NEJ.\n",
    "- **FP (False Positive):** Falskt larm (gissade JA, var NEJ).\n",
    "- **FN (False Negative):** Miss (gissade NEJ, var JA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822eb1c2",
   "metadata": {},
   "source": [
    "## Resonemangsfrågor\n",
    "\n",
    "### Resonemang kring Accuracy (Träffsäkerhet) vs andra mått\n",
    "Accuracy (andel rätt gissningar totalt) kan vara vilseledande.\n",
    "\n",
    "Exempel: Om 99 personer är friska och 1 har cancer. Om modellen gissar \"Frisk\" på alla, har den 99% accuracy. Men den är värdelös för att hitta cancern.\n",
    "\n",
    "Därför behöver vi:\n",
    "- **Precision:** Av alla vi gissade var sjuka, hur många var det? (Vill undvika falska larm.)\n",
    "- **Recall:** Av alla som faktiskt var sjuka, hur många hittade vi? (Vill undvika att missa fall.)\n",
    "- **F1-score:** Ett harmoniskt medelvärde av precision och recall. Bra balans.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
