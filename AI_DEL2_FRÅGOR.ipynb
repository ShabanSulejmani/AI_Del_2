{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kunskapskontroll Del 2 - AI & Maskininlärning\n",
    "**Namn:** Saban Sulejmani\n",
    "\n",
    "\n",
    "Denna notebook innehåller svar på fakta- och resonemangsfrågor för kapitel 7, 8 och 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Kapitel 7 - Artificiella Neurala Nätverk (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faktafrågor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Vad refererar \"djup\" till i begreppet \"djupinlärning\"?**\n",
    "\n",
    "\"Djup\" syftar på antalet dolda lager (hidden layers) i nätverket. Ett \"grunt\" nätverk kanske bara har ett enda dolt lager, medan \"Deep Learning\" (djupinlärning) handlar om nätverk med många lager staplade på varandra. Det är detta djup som låter modellen lära sig hierarkiska mönster (från enkla linjer till komplexa former)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Förklara vad som händer i figur 7.2, 7.3, figur 7.4 och figur 7.5. Varför används aktiveringsfunktioner?**\n",
    "\n",
    "Här följer en analys av figurerna som beskriver övergången från enkla till komplexa nätverk:\n",
    "\n",
    "* **Figur 7.2 :** \n",
    "    \n",
    "  En enkel perceptron med två inputs (1 och X₁) och ett output-lager. Vikterna W₁ och W₂ multipliceras med inputs och summeras till W₁ + W₂X₁. Detta är ett linjärt nätverk som bara kan dra raka linjer genom data.\n",
    "\n",
    "* **Figur 7.3 :** \n",
    "   \n",
    "    Ett nätverk med tre lager: input layer (1 och X₁), hidden layer (två noder), och output layer. Varje koppling har en vikt (W₁-W₆). Det dolda lagret gör att nätverket kan lära sig icke-linjära mönster, till skillnad från den enkla perceptronen.\n",
    "\n",
    "* **Figur 7.4 :** \n",
    "  \n",
    "    Visar två vanliga aktiveringsfunktioner: Sigmoid σ(z) = 1/(1+e⁻ᶻ) som ger värden mellan 0 och 1, och ReLU(z) = max(0,z) som är noll för negativa värden och linjär för positiva. Dessa inför icke-linearitet i nätverket.\n",
    "\n",
    "* **Figur 7.5 :** \n",
    "   \n",
    "   En single-layer perceptron med aktiveringsfunktion. Till skillnad från figur 7.2 inkluderar denna sigmoid-funktionen (1/(1+e^-z)) som omvandlar den linjära summan till ett värde mellan 0 och 1.\n",
    "\n",
    "**Varför används aktiveringsfunktioner?**\n",
    "Utan aktiveringsfunktioner skulle hela nätverket, oavsett hur många lager det har, bara vara en enda stor linjär multiplikation (som en enkel perceptron). Aktiveringsfunktionen inför **icke-linearitet**. Det är den magiska ingrediensen som gör att nätverket kan lära sig komplexa, böjda former och mönster, inte bara raka linjer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Har neurala nätverk få eller många parametrar?**\n",
    "\n",
    "Generellt sett har de **väldigt många** parametrar. Varje koppling (pil) mellan två neuroner har en vikt (weight), och varje neuron har ofta en bias. I djupa nätverk kan detta snabbt bli miljontals parametrar, vilket är anledningen till att de kräver mycket data och datorkraft för att tränas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Förklara intuitivt hur dropout-regularisering fungerar.**\n",
    "\n",
    "Tänk dig ett fotbollslag där man på varje träning slumpmässigt skickar hem 20% av spelarna.\n",
    "\n",
    "* Resultatet? Ingen kan luta sig tillbaka och lita på att \"stjärnspelaren\" (en viss neuron) ska göra allt jobb, för den kanske inte är där.\n",
    "* Alla spelare (neuroner) tvingas lära sig spelet och ta ansvar.\n",
    "\n",
    "I tekniska termer: Under träning stänger vi slumpmässigt av neuroner (sätter deras output till 0). Detta förhindrar **överanpassning (overfitting)** eftersom nätverket inte kan memorera exakta vägar genom nätet, utan måste lära sig robusta, generella mönster som fungerar oavsett vilka noder som är aktiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resonemangsfrågor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Din kollega ber dig förklara tabell 7.1 och tabell 7.2. Gör det!**\n",
    "\n",
    "\n",
    "\n",
    "* **Tabell 7.1 :** Visar typiska hyperparametrar för MLP vid regressionsproblem: antal input-neuroner (en per feature), 1-5 hidden layers med 10-100 neuroner per lager, ReLU som hidden activation, och MSE eller MAE som loss-funktion.\n",
    "* **Tabell 7.2 :** Visar typiska hyperparametrar för MLP vid klassificeringsproblem. För binär klassificering: 1 output-neuron med Logistic activation. För multilabel: 1 output per label med Logistic. För multiklass: 1 output per klass med Softmax. Alla använder Cross entropy som loss-funktion.\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Förklara översiktligt hur backpropagation fungerar. Använd figur 7.7 till din hjälp.**\n",
    "\n",
    "\n",
    "\n",
    "Backpropagation är metoden nätverket använder för att lära sig av sina misstag. Processen sker i tre steg (som ofta syns i figur 7.7):\n",
    "\n",
    "1.  **Forward Pass (Gissning):** Data skickas genom nätverket, från input till output, och nätverket gör en gissning.\n",
    "2.  **Beräkna felet (Loss):** Vi jämför gissningen med facit. Hur fel hade vi?\n",
    "3.  **Backward Pass (Skyll på vikterna):** Det är här magin sker. Vi skickar felet *baklänges* genom nätverket (från höger till vänster i figuren). Med hjälp av matematik (kedjeregeln/derivata) räknar vi ut hur mycket varje enskild vikt i nätverket bidrog till felet.\n",
    "4.  **Uppdatera:** Vi justerar vikterna lite grann i motsatt riktning av felet (Gradient Descent) för att minska felet nästa gång.\n",
    "\n",
    "Kortfattat: \"Gissa -> Mät felet -> Gå tillbaka och justera rattarna -> Gissa igen.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Kapitel 8 - Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faktafrågor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Vad krävs det för att ett neuralt nätverk ska klassas som CNN?**\n",
    "\n",
    "Det krävs att nätverket innehåller minst ett **Convolutional Layer** (faltningslager). Det är detta lager som använder filter (kernels) för att skanna av bilden, till skillnad från vanliga \"Dense layers\" där alla noder är kopplade till alla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Inom vilket tillämpningsområde är CNN generellt sett en väldigt kraftfull modell?**\n",
    "\n",
    "Inom **bildanalys** (Computer Vision). Det är standardmodellen för att känna igen objekt i bilder, ansiktsigenkänning, medicinsk bildanalys, och även video. De är överlägsna här eftersom de tar hänsyn till pixlarnas placering i förhållande till varandra (spatial struktur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Vad menas med RGB?**\n",
    "\n",
    "RGB står för **Red, Green, Blue**. Det är så digitala färgbilder byggs upp.\n",
    "En färgbild är inte bara en platt matris, utan den har ett \"djup\" på 3 kanaler (Röd, Grön, Blå). Varje pixel består av tre värden som blandas. För ett CNN innebär detta att input-lagret måste hantera tre dimensioner (Höjd, Bredd, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Vad är data augmentation?**\n",
    "\n",
    "Det är ett knep för att artificiellt skapa mer träningsdata och minska överanpassning.\n",
    "Vi tar våra befintliga bilder och modifierar dem slumpmässigt: vi kanske roterar dem, vänder dem spegelvänt (flip), zoomar in lite eller ändrar ljusstyrkan.\n",
    "*Varför?* Om modellen lär sig känna igen en katt oavsett om den tittar åt höger eller vänster, blir modellen mycket smartare och robustare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resonemangsfrågor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Förklara översiktligt hur CNN fungerar. Använd begreppen convolution layer och pooling layer i ditt svar.**\n",
    "\n",
    "Ett CNN fungerar lite som det mänskliga ögat bearbetar synintryck – i steg.\n",
    "\n",
    "1.  **Convolution Layer (Faltning):** Detta är \"detektiven\". Vi drar små filter (kernels) över bilden. Dessa filter lär sig att reagera på specifika mönster. I början hittar de enkla saker som kanter och streck. Djupare in i nätverket kombineras dessa till former (ögon, öron) och slutligen hela objekt (katt).\n",
    "\n",
    "2.  **Pooling Layer (Förminskning):** Detta är \"sammanfattaren\". Efter att convolution-lagret hittat mönster, använder vi pooling (ofta Max Pooling) för att kasta bort onödig detaljinformation och krympa bilden. Vi behåller bara det viktigaste (t.ex. \"ja, det fanns en kant här\"). Detta gör modellen snabbare och mindre känslig för exakt *var* i bilden objektet befinner sig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Din kollega ber dig förklara figur 8.4. Gör det!**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Figur 8.4 visar den typiska arkitekturen för ett CNN.\n",
    "\n",
    "1.  **Vänster (Input):** Vi stoppar in en bild (t.ex. en bil).\n",
    "2.  **Mitten (Feature Extraction):** Här ser vi block av \"Convolution + ReLU + Pooling\".    Blocken blir *djupare* (fler filter/features) men *mindre till ytan* (p.g.a. pooling). Nätverket omvandlar bilden från pixlar till abstrakta begrepp (hjul, fönster).\n",
    "3.  **Höger (Classification):** När bilden är tillräckligt bearbetad och förminskad, \"plattas den till\" (Flatten) till en lång rad siffror. Dessa kopplas till ett vanligt neuralt nätverk (Fully Connected Layer) som gör själva beslutet: \"Är detta en bil eller en cykel?\".\n",
    "4.  **Output:** Sista lagret ger sannolikheten för varje klass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Kapitel 10 - Chattbottar & RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faktafrågor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Vad är prompt engineering?**\n",
    "\n",
    "Prompt engineering är konsten att formulera instruktioner (prompts) till en AI-modell för att få bästa möjliga resultat. Det handlar om att vara tydlig, ge kontext och styra modellen. Istället för att bara fråga \"Skriv ett mail\", kanske man skriver: \"Agera som en senior säljare och skriv ett kort, formellt mail till en ny kund...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Vad är RAG?**\n",
    "\n",
    "RAG står för **Retrieval-Augmented Generation**.\n",
    "Språkmodeller (som ChatGPT) kan ibland hallucinera eller ha gammal kunskap. RAG löser detta genom att ge modellen tillgång till ett \"bibliotek\" (extern data).\n",
    "Processen:\n",
    "1.  Användaren ställer en fråga.\n",
    "2.  Systemet söker upp (Retrieval) relevant information i en databas (t.ex. företagets PDF-filer).\n",
    "3.  Systemet klistrar in informationen i prompten till AI:n (Augmented).\n",
    "4.  AI:n genererar svaret baserat på faktat den just fick (Generation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Vad är chunking och embeddings?**\n",
    "\n",
    "För att RAG ska fungera måste vi hantera texten smart:\n",
    "\n",
    "* **Chunking:** Vi kan inte skicka in en hel bok till AI:n på en gång. Därför delar vi upp texten i mindre, hanterbara bitar (chunks), t.ex. stycken på 500 ord.\n",
    "* **Embeddings:** Datorer förstår inte ord, de förstår siffror. Embeddings är processen att översätta text (våra chunks) till långa listor av tal (vektorer). Det magiska är att texter med liknande *betydelse* får liknande *siffror*. Det gör att vi kan söka efter *innebörd* snarare än bara nyckelord."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resonemangsfrågor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Förklara översiktligt hur man kan evaluera en chattbot.**\n",
    "\n",
    "Att utvärdera en chattbot är svårare än vanlig ML (där vi har rätt/fel svar). Språk är subjektivt.\n",
    "* **Mänsklig utvärdering:** Man låter testpersoner chatta med boten och betygsätta svaren (Bra/Dåligt, Relevant/Irrelevant).\n",
    "* **LLM-as-a-Judge:** Man använder en *annan*, smartare modell (t.ex. GPT-4) för att rätta svaren från sin egen bot. Man ger den kriterier: \"Var svaret artigt? Var det korrekt baserat på texten?\".\n",
    "* **RAG-metrics:** För RAG mäter man specifikt: Hittade vi rätt dokument? Svarade boten troget mot dokumentet eller hittade den på?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Din kollega frågar dig vad ELIZA och Turingtestet är.**\n",
    "\n",
    "* **ELIZA (1966):** En av världens första chattbottar. Den simulerade en psykoterapeut genom väldigt enkel mönstermatchning. Om du sa \"Jag är ledsen över min mamma\", svarade den \"Berätta mer om din mamma\". Den förstod ingenting egentligen, men lyckades ändå lura folk att den kände empati.\n",
    "* **Turingtestet:** Ett tankeexperiment föreslaget av Alan Turing 1950. Det går ut på att en domare chattar med en människa och en maskin. Om domaren inte kan avgöra vem som är vem, har maskinen \"klarat\" testet och anses (i någon mening) intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Ge konkreta exempel på hur olika företag kan ta nytta av chattbottar samt vilka risker som finns.**\n",
    "\n",
    "**Nytta:**\n",
    "* **Kundtjänst 24/7:** Ett e-handelsbolag kan svara på frågor om leverans och returer direkt, dygnet runt, utan personalkostnad.\n",
    "* **Intern kunskapsbank (RAG):** Ett ingenjörsföretag kan låta nyanställda fråga en bot \"Hur fungerar process X?\" och boten svarar baserat på alla interna manualer.\n",
    "\n",
    "**Risker:**\n",
    "* **Hallucinationer:** Boten kan hitta på fakta (\"Vår produkt klarar 200 grader\" när den bara klarar 100), vilket kan leda till stämningar eller farliga situationer.\n",
    "* **Bias/Olämpliga svar:** Om boten tränats på dålig data kan den uttrycka sig rasistiskt eller otrevligt, vilket skadar varumärket.\n",
    "* **Säkerhet:** \"Prompt Injection\" – användare kan lura boten att avslöja företagshemligheter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
